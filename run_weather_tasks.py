import argparse
import os
import torch
import numpy as np
import time
from exp_custom import Exp_Custom


# ä»»åŠ¡å®šä¹‰ï¼ˆå¯¹é½ LSTMï¼‰
TASKS = [
    (24, 1, "single_point"),
    (96, 1, "single_point"),
    (24, 6, "single_point"),
    (96, 6, "single_point"),
    (96, 6, "sequence"),
    (96, 24, "single_point"),
    (96, 24, "sequence"),
]


def get_args(window_size, horizon, task_type, data_path):
    """
    ç”Ÿæˆå®éªŒå‚æ•°
    å®Œå…¨å¯¹é½ LSTM çš„è¶…å‚æ•°è®¾ç½®
    """
    parser = argparse.ArgumentParser(description='Informer for Weather Prediction')

    # åŸºæœ¬é…ç½®
    parser.add_argument('--model', type=str, default='informer', help='model name')
    parser.add_argument('--data', type=str, default='custom', help='data type')
    parser.add_argument('--root_path', type=str, default='./data/', help='root path of data')
    parser.add_argument('--data_path', type=str, default=data_path, help='data file')
    parser.add_argument('--features', type=str, default='MS', help='M: multivariate, MS: multivariate predict univariate, S: univariate')
    parser.add_argument('--target', type=str, default='temperature', help='target feature')
    parser.add_argument('--freq', type=str, default='h', help='h: hourly')
    parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='checkpoints directory')

    # æ•°æ®å°ºå¯¸
    parser.add_argument('--seq_len', type=int, default=window_size, help='input sequence length')
    parser.add_argument('--label_len', type=int, default=0, help='start token length (è®¾ä¸º0)')
    parser.add_argument('--pred_len', type=int, default=horizon, help='prediction sequence length')
    
    # æ¨¡å‹å‚æ•°ï¼ˆå¯¹é½ LSTM çš„å¤æ‚åº¦ï¼‰
    parser.add_argument('--enc_in', type=int, default=92, help='encoder input size (ç‰¹å¾æ•°)')   # å®é™…æ£€æŸ¥ç‰¹å¾æ•°ä¸º92
    parser.add_argument('--dec_in', type=int, default=92, help='decoder input size')
    parser.add_argument('--c_out', type=int, default=1, help='output size (é¢„æµ‹ temperature)')
    parser.add_argument('--d_model', type=int, default=64, help='dimension of model (å¯¹é½ LSTM hidden_size)')
    parser.add_argument('--n_heads', type=int, default=4, help='num of heads')
    parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers (å¯¹é½ LSTM num_layers)')
    parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')
    parser.add_argument('--d_ff', type=int, default=256, help='dimension of fcn')
    parser.add_argument('--factor', type=int, default=5, help='probsparse attn factor')
    parser.add_argument('--padding', type=int, default=0, help='padding type')
    parser.add_argument('--distil', action='store_false', help='whether to use distilling in encoder', default=True)
    parser.add_argument('--dropout', type=float, default=0.2, help='dropout (å¯¹é½ LSTM)')
    parser.add_argument('--attn', type=str, default='prob', help='attention used in encoder')
    parser.add_argument('--embed', type=str, default='timeF', help='time features encoding')
    parser.add_argument('--activation', type=str, default='gelu', help='activation')
    parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')
    parser.add_argument('--mix', action='store_false', help='use mix attention in generative decoder', default=True)

    # è®­ç»ƒç­–ç•¥ï¼ˆå®Œå…¨å¯¹é½ LSTMï¼‰
    parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')
    parser.add_argument('--train_epochs', type=int, default=100, help='train epochs (å¯¹é½ LSTM)')
    parser.add_argument('--batch_size', type=int, default=64, help='batch size (å¯¹é½ LSTM)')
    parser.add_argument('--patience', type=int, default=10, help='early stopping patience (å¯¹é½ LSTM)')
    parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate (å¯¹é½ LSTM)')
    parser.add_argument('--loss', type=str, default='mse', help='loss function')
    parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')
    parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)

    # GPU
    parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')
    parser.add_argument('--gpu', type=int, default=0, help='gpu')
    parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)
    parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')
    
    # ä»»åŠ¡ç±»å‹ï¼ˆè‡ªå®šä¹‰å­—æ®µï¼‰
    parser.add_argument('--task_type', type=str, default=task_type, help='single_point or sequence')

    args = parser.parse_args([])  # ç©ºåˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
    
    # æ£€æŸ¥ GPU å¯ç”¨æ€§
    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False
    if args.use_gpu and args.use_multi_gpu:
        args.devices = args.devices.replace(' ', '')
        device_ids = args.devices.split(',')
        args.device_ids = [int(id_) for id_ in device_ids]
        args.gpu = args.device_ids[0]

    return args


def run_single_task(window_size, horizon, task_type, data_path, city_name):
    """
    è¿è¡Œå•ä¸ªä»»åŠ¡
    """
    print(f"\n{'='*80}")
    print(f"Running Task: Window={window_size}, Horizon={horizon}, Type={task_type}")
    print(f"City: {city_name}")
    print(f"{'='*80}\n")
    
    # è·å–å‚æ•°
    args = get_args(window_size, horizon, task_type, data_path)
    
    # è®¾ç½®éšæœºç§å­ï¼ˆå¯¹é½ LSTMï¼‰
    fix_seed = 2021
    torch.manual_seed(fix_seed)
    np.random.seed(fix_seed)
    
    # åˆ›å»ºå®éªŒ
    setting = f'{city_name}_informer_w{window_size}_h{horizon}_{task_type}'
    exp = Exp_Custom(args)
    
    # è®°å½•è®­ç»ƒæ—¶é—´
    train_start = time.time()
    
    # è®­ç»ƒ
    print('>>>>>>>start training >>>>>>>>>>>>>>>>>>>>>>>>>>')
    exp.train(setting)
    train_time = time.time() - train_start
    
    # æµ‹è¯•
    print('>>>>>>>testing >>>>>>>>>>>>>>>>>>>>>>>>>>')
    mae, rmse, r2, inference_time = exp.test(setting)
    
    print(f'\nTask Completed!')
    print(f'Training Time: {train_time:.2f}s')
    print(f'Inference Time: {inference_time:.2f}s')
    
    return {
        'window': window_size,
        'horizon': horizon,
        'task_type': task_type,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'train_time': train_time,
        'inference_time': inference_time
    }


def run_all_tasks_for_city(data_path, city_name):
    """
    ä¸ºå•ä¸ªåŸå¸‚è¿è¡Œæ‰€æœ‰ 7 ä¸ªä»»åŠ¡
    """
    results = []
    
    for window_size, horizon, task_type in TASKS:
        result = run_single_task(window_size, horizon, task_type, data_path, city_name)
        results.append(result)
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    results_dir = './results_summary/'
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    report_path = os.path.join(results_dir, f'{city_name}_informer_results.md')
    generate_report(results, city_name, report_path)
    
    print(f"\n{'='*80}")
    print(f"All tasks completed for {city_name}!")
    print(f"Results saved to: {report_path}")
    print(f"{'='*80}\n")
    
    return results


def generate_report(results, city_name, output_path):
    """
    ç”Ÿæˆ Markdown æ ¼å¼çš„ç»“æœæŠ¥å‘Š
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(f"# Informer Results - {city_name}\n\n")
        f.write("## Summary Table\n\n")
        f.write("| Task | Window | Horizon | Type | MAE | RMSE | RÂ² | Train Time (s) | Inference Time (s) |\n")
        f.write("|------|--------|---------|------|-----|------|-------|----------------|-------------------|\n")
        
        for i, res in enumerate(results, 1):
            f.write(f"| {i} | {res['window']} | {res['horizon']} | {res['task_type']} | "
                   f"{res['mae']:.4f} | {res['rmse']:.4f} | {res['r2']:.4f} | "
                   f"{res['train_time']:.2f} | {res['inference_time']:.2f} |\n")
        
        f.write("\n## Detailed Results\n\n")
        for i, res in enumerate(results, 1):
            f.write(f"### Task {i}: Window={res['window']}, Horizon={res['horizon']}, Type={res['task_type']}\n\n")
            f.write(f"- **MAE**: {res['mae']:.6f}\n")
            f.write(f"- **RMSE**: {res['rmse']:.6f}\n")
            f.write(f"- **RÂ²**: {res['r2']:.6f}\n")
            f.write(f"- **Training Time**: {res['train_time']:.2f}s\n")
            f.write(f"- **Inference Time**: {res['inference_time']:.2f}s\n\n")


if __name__ == '__main__':
    """
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    
    python run_weather_tasks.py
    
    ä½ éœ€è¦ä¿®æ”¹ä¸‹é¢çš„å‚æ•°ï¼š
    - data_path: ä½ çš„æ•°æ®æ–‡ä»¶å
    - city_name: åŸå¸‚åç§°
    """
    
    # ============== é…ç½®åŒºåŸŸ ==============
    data_path = 'Albuquerque_wide.csv'  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®æ–‡ä»¶å
    city_name = 'Albuquerque_wide'            # ä¿®æ”¹ä¸ºåŸå¸‚åç§°
    # =====================================
    
    # è¿è¡Œæ‰€æœ‰ä»»åŠ¡
    results = run_all_tasks_for_city(data_path, city_name)
    
    print("\nğŸ‰ All tasks completed successfully!")